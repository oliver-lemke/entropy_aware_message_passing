# This file acts as the base configuration file for the project.
# See configs/template.yaml for an example how to create a deviating configuration file
# By default the config/user.yaml configuration file is used.
seed: 0

# used for naming purposes
note: "init"

#######################################################################################
################################### MODEL PARAMETERS ##################################
#######################################################################################

# the type of solution to run
# can be any in ["basic_gcn", "hrnet_gcn", "entropic_gcn", "pairnorm_gcn", "g2"]
model_type: "entropic_gcn"

# can be any in ["train", "test"]
run_type: "train"

model_parameters:
    basic_gcn:
        pretrained_weights: null
        depth: 64
        hidden_dim: 256
    entropic_gcn:
        pretrained_weights: null
        depth: 64
        hidden_dim: 256
        temperature:
            learnable: False
            value: 10.0
        weight:
            learnable: False
            value: 1.0
        normalize_energies: True
        normalize_distribution: False
        scale_by_temperature: False
    pairnorm_gcn:
        pretrained_weights: null
        depth: 64
        hidden_dim: 256
        dropout: 0
        residual: 0
        norm_mode: "PN-SI"
        norm_scale: 3
        normalize_feature: True
    g2:
        pretrained_weights: null
        depth: 64
        hidden_dim: 256
        use_gg_conv: true
        conv_type: "GCN"
        dropout: 0
        input_dropout: 0
        p: 2.0
    hrnet_gcn:
        pretrained_weights: null
        depth: 8
        hidden_dim: 256
        branches:
            - 0
            - 2
            - 4
            - 6

# can be in [basic_gcn]
conv_block_args:
    block_type: "basic_gcn"
    basic_gcn:
        depth: 2
        hidden_dim: 256
        dropout_rate: 0.0
# can be in [sum, mean, max, simple_conv, simple_attention]
fusion_block_args:
    block_type: "simple_conv"
    simple_conv:
        depth: 2
        hidden_dim: 128
        residual: True
    simple_attention:
        # can be in [per_node, per_element]
        attention_type: "per_node"
        attention_depth: 2
        attention_hidden_dim: 256
        depth: 2
        hidden_dim: 256
        residual: True
# can be in [id, full]
transform_block_args:
    block_type: "full"
    full:
        depth: 2
        hidden_dim: 128
        residual: True
# can be in [single, sum, mean, max, simple_conv, simple_attention]
output_block_args:
    block_type: "mean"
    single:
        branch_index: 0
    simple_conv:
        depth: 2
        hidden_dim: 16
    simple_attention:
        # can be in [per_node, per_element]
        attention_type: "per_node"
        attention_depth: 2
        attention_hidden_dim: 256
        depth: 2
        hidden_dim: 256


tester:
    model_types:
        - "pairnorm_gcn"
    depths:
        - 1
        - 10
        - 50
        - 100
        - 200
        - 300
        - 400
        - 500
        - 600
        - 700
        - 800
        - 900
        - 1000


#######################################################################################
################################## DATASET PARAMETERS #################################
#######################################################################################

# can be in ["planetoid", "faust", "mnist"]
dataset: "planetoid"
multi_graph_dataset: false

dataset_parameters:
    planetoid:
        name: "Cora"
    long_range:
        name: "PascalVOC-SP"


#######################################################################################
######################################## OTHER ########################################
#######################################################################################

hyperparameters:
    train:
        batch_size: 5
        learning_rate: 0.001
        weight_decay: 0
        epochs: 100
        save_every: 100
    val:
        batch_size: 4096

# device on which to train
device: "cpu"

# whether to resume training from earlier model
resume_training: False

# paths are relative from project_root_directory
subpaths:
    data: "resources/data/"
    cache: "resources/cache/"
    logs: "resources/logs/"
    output: "resources/output/"
    resume_from: "path/to/weights"
    pretrained_weights: "resources/pretrained_weights"

save_names:
    weights: "weights.pth"
    optimizer: "optimizer.pth"
    pretrained_metadata: "pretrained_metadata.json"

wandb:
    enable: True
    # whether to plot extra plots
    extended: False
    entity: "gnn_dl"
    project: "Init Tests"
    group: null

logging:
    # DEBUG, INFO, WARNING, ERROR, CRITICAL
    console: "DEBUG"
    wandb: "DEBUG"